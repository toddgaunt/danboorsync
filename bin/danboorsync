#!/usr/bin/env python3

# module imports
from danboorsync import danbooru
from danboorsync import logger
from danboorsync import util
from danboorsync.args import parse_args

def main():
    args = parse_args()
    lg = logger.logger("danboorsync", args.verbose)

    # Change directory to the target download directory,
    # then download all pages specified
    with util.cd(args.output):
        # Calculate all md5sums in target download directory
        md5sums = util.get_file_md5sums()
        for number in args.pages:
            # Append which page to be downloaded as a query on the url
            page_url = danbooru.appendqueries(args.url, \
                    ["page={}".format(number)])
            # Download the json file into a list
            json = danbooru.jsonize(page_url)
            # Transform the json list into a list of post objects
            posts = danbooru.extract_image_posts(json)
            for post in posts:
                if post.md5sum not in md5sums:
                    filename = danbooru.download_post(post, "http", \
                            "danbooru.donmai.us")
                    logger.info(lg, "{} downloaded".format(filename))
                    # Add the new file to the dict of calculated md5sums
                    md5sums[post.md5sum] = filename
                else:
                    logger.info(lg, "md5sum match \"{}\" -> \"{}\"".format( \
                            md5sums[post.md5sum], post.md5sum))

if __name__ == "__main__":
    main()
